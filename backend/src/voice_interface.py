"""
éŸ³å£°ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹å®Ÿè£…
éŸ³å£°ã«ã‚ˆã‚‹å¯¾è©±å…¥åŠ›ã¨éŸ³å£°èª­ã¿ä¸Šã’æ©Ÿèƒ½
"""

import asyncio
import logging
from typing import Dict, Optional, List, Any, Callable
from datetime import datetime
import streamlit as st
import io
import base64

# éŸ³å£°å‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import speech_recognition as sr
    import pyttsx3
    import wave
    import sounddevice as sd
    from pydub import AudioSegment

    AUDIO_AVAILABLE = True
except ImportError:
    logging.warning("Audio libraries not available. Install: pip install SpeechRecognition pyttsx3 pydub sounddevice")
    AUDIO_AVAILABLE = False

logger = logging.getLogger(__name__)


class VoiceInterface:
    """éŸ³å£°ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚¯ãƒ©ã‚¹"""

    def __init__(self, language: str = "ja-JP"):
        self.language = language
        self.is_recording = False
        self.recognizer = None
        self.tts_engine = None

        if AUDIO_AVAILABLE:
            self.recognizer = sr.Recognizer(language)
            self.tts_engine = pyttsx3.init()
            self.microphone = None

    async def setup_microphone(self) -> bool:
        """ãƒã‚¤ã‚¯ãƒ•ã‚©ãƒ³ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        if not AUDIO_AVAILABLE:
            return False

        try:
            # åˆ©ç”¨å¯èƒ½ãªãƒã‚¤ã‚¯ãƒ•ã‚©ãƒ³ã‚’å–å¾—
            devices = sr.Microphone.list_microphone_names()

            if devices:
                self.microphone = devices[0]  # æœ€åˆã®ãƒ‡ãƒã‚¤ã‚¹ã‚’ä½¿ç”¨
                logger.info(f"Microphone setup: {self.microphone}")
                return True
            else:
                logger.warning("No microphone found")
                return False

        except Exception as e:
            logger.error(f"Microphone setup failed: {e}")
            return False

    async def start_voice_input(self, callback: Callable[[str], None]) -> bool:
        """éŸ³å£°å…¥åŠ›ã‚’é–‹å§‹"""
        if not AUDIO_AVAILABLE:
            st.error("éŸ³å£°æ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return False

        try:
            self.is_recording = True

            # ãƒã‚¤ã‚¯ãƒ•ã‚©ãƒ³ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
            if not await self.setup_microphone():
                return False

            st.session_state.voice_input_active = True

            # éŸ³å£°èªè­˜ã®å®Ÿè¡Œ
            with sr.Microphone(device_index=0) as source:
                st.info("ğŸ¤ éŸ³å£°å…¥åŠ›é–‹å§‹ - åœæ­¢ã™ã‚‹ã«ã¯ã€Œåœæ­¢ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯")

                recognizer = sr.Recognizer(self.language)
                audio_data = []

                while self.is_recording:
                    try:
                        audio = recognizer.listen(source, timeout=1)
                        audio_data.append(audio)

                        # ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤º
                        self._update_audio_display(audio_data)

                    except sr.WaitTimeoutError:
                        continue
                    except KeyboardInterrupt:
                        break
                    except Exception as e:
                        logger.error(f"Audio recording error: {e}")
                        break

            # éŒ²ã‚Šè¾¼ã¿å®Œäº†
            if audio_data:
                st.success("ğŸ¤ éŸ³å£°èªè­˜ä¸­...")
                transcription = self._transcribe_audio(audio_data)
                callback(transcription)
                return True

        except Exception as e:
            logger.error(f"Voice input failed: {e}")
            self.is_recording = False
            st.session_state.voice_input_active = False
            return False

    def _transcribe_audio(self, audio_data: List) -> str:
        """éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›"""
        if not audio_data:
            return ""

        try:
            # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
            audio_segment = AudioSegment.empty()
            for audio in audio_data:
                audio_segment += audio

            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_file:
                audio_segment.export(temp_file.name, format="wav")

                # éŸ³å£°èªè­˜
                with sr.AudioFile(temp_file.name) as source:
                    recognizer = sr.Recognizer(self.language)
                    text = recognizer.record(source=source, duration=len(audio_segment))
                    return text

        except Exception as e:
            logger.error(f"Transcription failed: {e}")
            return "éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼"

    def _update_audio_display(self, audio_data: List):
        """éŸ³å£°å…¥åŠ›ã®è¡¨ç¤ºã‚’æ›´æ–°"""
        # ç°¡æ³¢å™¨ã‚’è¡¨ç¤º
        if len(audio_data) > 0:
            audio_wave = np.concatenate([np.frombuffer(a.get_raw_data(), dtype=np.int16) for a in audio_data])

            # Streamlitã§æ³¢å½¢è¡¨ç¤º
            fig = {
                "data": [{"x": list(range(len(audio_wave))), "y": audio_wave.tolist()}],
                "layout": {
                    "height": 100,
                    "margin": {"t": 0, "b": 0, "l": 0, "r": 0},
                    "yaxis": {"showgrid": False, "zeroline": False},
                    "xaxis": {"showgrid": False, "zeroline": False},
                },
            }

            st.session_state.audio_visualization = fig
            st.experimental_rerun()

    def stop_voice_input(self):
        """éŸ³å£°å…¥åŠ›ã‚’åœæ­¢"""
        self.is_recording = False
        st.session_state.voice_input_active = False
        logger.info("Voice input stopped")

    async def speak_text(self, text: str, voice_id: Optional[str] = None) -> bool:
        """ãƒ†ã‚­ã‚¹ãƒˆã‚’éŸ³å£°ã§èª­ã¿ä¸Šã’"""
        if not AUDIO_AVAILABLE or not text.strip():
            return False

        try:
            # TTSã‚¨ãƒ³ã‚¸ãƒ³ã®åˆæœŸåŒ–
            if not self.tts_engine:
                self.tts_engine = pyttsx3.init()

            # éŸ³å£°è¨­å®š
            self.tts_engine.setProperty("rate", 150)
            self.tts_engine.setProperty("volume", 1.0)

            if voice_id:
                self.tts_engine.setProperty("voice", voice_id)

            # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ
            with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as temp_file:
                self.tts_engine.save_to_file(temp_file.name, text)

                # éŸ³å£°å†ç”Ÿ
                st.info(f"ğŸ”Š å†ç”Ÿä¸­: {text[:50]}...")

                # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’Base64ã«å¤‰æ›
                with open(temp_file.name, "rb") as f:
                    audio_data = f.read()
                    audio_base64 = base64.b64encode(audio_data).decode()

                # å†ç”Ÿ
                st.audio(audio_base64, format="audio/mp3")

                return True

        except Exception as e:
            logger.error(f"Text-to-speech failed: {e}")
            return False

    def get_available_voices(self) -> List[Dict[str, str]]:
        """åˆ©ç”¨å¯èƒ½ãªéŸ³å£°ã‚’å–å¾—"""
        if not AUDIO_AVAILABLE:
            return []

        try:
            voices = self.tts_engine.getProperty("voices")
            voice_list = []

            for i, voice in enumerate(voices):
                voice_info = {
                    "id": str(i),
                    "name": voice.name,
                    "gender": voice.gender,
                    "age": voice.age,
                    "languages": voice.languages,
                }
                voice_list.append(voice_info)

            return voice_list

        except Exception as e:
            logger.error(f"Get voices failed: {e}")
            return []

    def is_audio_available(self) -> bool:
        """éŸ³å£°æ©Ÿèƒ½ãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯"""
        return AUDIO_AVAILABLE


class VoiceCommands:
    """éŸ³å£°ã‚³ãƒãƒ³ãƒ‰å‡¦ç†ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.commands = {
            # ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæ“ä½œ
            "portfolio": ["ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ª", "ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªç¢ºèª", "ãƒã‚¸ã‚·ãƒ§ãƒ³"],
            "trade": ["è²·ã„", "å£²ã‚Š", "å–å¼•", "æ³¨æ–‡"],
            "analysis": ["åˆ†æ", "åˆ†æã—ã¦", "ãƒãƒ£ãƒ¼ãƒˆ", "ã‚°ãƒ©ãƒ•"],
            "settings": ["è¨­å®š", "ã‚ªãƒ—ã‚·ãƒ§ãƒ³", "ç’°å¢ƒè¨­å®š"],
            # AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ
            "assistant": ["ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ", "AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ", "ãƒãƒ£ãƒƒãƒˆ"],
            # å¸‚å ´æƒ…å ±
            "market": ["å¸‚å ´", "ç›¸å ´", "çŠ¶æ³", "ãƒ‹ãƒ¥ãƒ¼ã‚¹"],
            # ã‚·ã‚¹ãƒ†ãƒ æ“ä½œ
            "system": ["ãƒ˜ãƒ«ãƒ—", "çµ‚äº†", "çµ‚äº†", "ãƒ›ãƒ¼ãƒ ", "ãƒ¡ãƒ‹ãƒ¥ãƒ¼"],
        }

        self.activated_commands = {
            "buy": "è²·ã„æ³¨æ–‡",
            "sell": "å£²ã‚Šæ³¨æ–‡",
            "portfolio_check": "ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªç¢ºèª",
            "start_trading": "å–å¼•é–‹å§‹",
            "show_analysis": "åˆ†æè¡¨ç¤º",
        }

    def process_voice_command(self, command_text: str, callback: Callable[[str, Dict], None]) -> None:
        """éŸ³å£°ã‚³ãƒãƒ³ãƒ‰ã‚’å‡¦ç†"""
        command_lower = command_text.lower().strip()

        # ã‚³ãƒãƒ³ãƒ‰ç¨®é¡ã‚’ç‰¹å®š
        command_type = self._identify_command_type(command_lower)

        if command_type:
            # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ
            callback(command_lower, {"type": command_type, "action": command_text})
            logger.info(f"Voice command executed: {command_type} - {command_text}")
        else:
            logger.warning(f"Unknown voice command: {command_text}")
            callback(command_lower, {"type": "unknown", "action": command_text})

    def _identify_command_type(self, text: str) -> str:
        """ã‚³ãƒãƒ³ãƒ‰ã‚¿ã‚¤ãƒ—ã‚’ç‰¹å®š"""

        # ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªé–¢é€£
        if any(keyword in text for keyword in self.commands["portfolio"]):
            return "portfolio"

        # å–å¼•é–¢é€£
        if any(keyword in text for keyword in self.commands["trade"]):
            if "è²·ã„" in text:
                return "buy"
            elif "å£²ã‚Š" in text:
                return "sell"
            else:
                return "trade"

        # åˆ†æé–¢é€£
        if any(keyword in text for keyword in self.commands["analysis"]):
            return "analysis"

        # è¨­å®šãƒ»ã‚·ã‚¹ãƒ†ãƒ é–¢é€£
        if any(keyword in text for keyword in self.commands["settings"] + self.commands["system"]):
            return "settings"

        # AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆé–¢é€£
        if any(keyword in text for keyword in self.commands["assistant"]):
            return "assistant"

        # å¸‚å ´é–¢é€£
        if any(keyword in text for keyword in self.commands["market"]):
            return "market"

        return "unknown"


class VoiceControlledUI:
    """éŸ³å£°åˆ¶å¾¡UI"""

    def __init__(self, voice_interface: VoiceInterface):
        self.voice = voice_interface
        self.voice_commands = VoiceCommands()
        self.last_command = None

    def show_voice_interface(self):
        """éŸ³å£°ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’è¡¨ç¤º"""
        st.subheader("ğŸ¤ éŸ³å£°ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹")

        # éŸ³å£°æ©Ÿèƒ½ã®çŠ¶æ…‹è¡¨ç¤º
        col1, col2, col3 = st.columns(3)

        with col1:
            if self.voice.is_audio_available():
                st.success("âœ… éŸ³å£°æ©Ÿèƒ½åˆ©ç”¨å¯èƒ½")
            else:
                st.error("âŒ éŸ³å£°æ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")

        with col2:
            if st.session_state.get("voice_input_active", False):
                st.info("ğŸ¤ å¾…æ©Ÿä¸­")
            else:
                st.info("ğŸ’¤ éã‚¢ã‚¯ãƒ†ã‚£ãƒ–")

        with col3:
            # éŸ³é‡èª¿æ•´
            volume = st.slider("éŸ³é‡", 0.0, 1.0, 0.8, key="voice_volume")

            # éŸ³å£°é¸æŠ
            if self.voice.is_audio_available():
                voices = self.voice.get_available_voices()
                if voices:
                    voice_names = [v["name"] for v in voices]
                    selected_voice = st.selectbox("éŸ³å£°é¸æŠ", voice_names, index=0, key="voice_selection")

        st.markdown("---")

        # éŸ³å£°å…¥åŠ›ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«
        col1, col2, col3 = st.columns(3)

        with col1:
            if st.button("ğŸ¤ éŒ²éŸ³é–‹å§‹", key="start_voice"):
                self.start_voice_recording()

        with col2:
            if st.button("â¹ï¸ éŒ²éŸ³åœæ­¢", key="stop_voice"):
                self.stop_voice_input()

        with col3:
            if st.button("ğŸ—‘ï¸ ã‚¯ãƒªã‚¢", key="clear_voice"):
                st.session_state.voice_transcript = []
                st.experimental_rerun()

        # éŸ³å£°å…¥åŠ›çµæœè¡¨ç¤º
        if "voice_transcript" in st.session_state and st.session_state.voice_transcript:
            st.subheader("ğŸ“ éŸ³å£°èªè­˜çµæœ")
            for i, text in enumerate(st.session_state.voice_transcript[-5:], 1):
                st.write(f"{i}. {text}")

        # ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œå±¥æ­´
        if "command_history" in st.session_state:
            st.subheader("ğŸ”§ ã‚³ãƒãƒ³ãƒ‰å±¥æ­´")
            for cmd in st.session_state.command_history[-5:]:
                st.write(f"ğŸ—£ï¸ {cmd['action']} ({cmd['timestamp'][:19]})")

        # éŸ³å£°ã‚³ãƒãƒ³ãƒ‰ãƒªã‚¹ãƒˆ
        st.subheader("ğŸ¤ éŸ³å£°ã‚³ãƒãƒ³ãƒ‰ä¸€è¦§")

        command_categories = {
            "ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæ“ä½œ": self.voice_commands.commands["portfolio"],
            "å–å¼•æ“ä½œ": self.voice_commands.commands["trade"],
            "åˆ†æãƒ»ç¢ºèª": self.voice_commands.commands["analysis"],
            "AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ": self.voice_commands.commands["assistant"],
            "è¨­å®šãƒ»ã‚·ã‚¹ãƒ†ãƒ ": self.voice_commands.commands["settings"] + self.voice_commands["system"],
            "å¸‚å ´æƒ…å ±": self.voice_commands.commands["market"],
        }

        for category, commands in command_categories.items():
            with st.expander(f"ğŸ“‹ {category}"):
                st.markdown(", ".join(commands))

        st.markdown("---")

        # éŸ³å£°èª­ã¿ä¸Šã’ãƒ†ã‚¹ãƒˆ
        st.subheader("ğŸ”Š éŸ³å£°èª­ã¿ä¸Šã’ãƒ†ã‚¹ãƒˆ")

        col1, col2 = st.columns(2)

        with col1:
            test_text = st.text_input("ãƒ†ã‚¹ãƒˆæ–‡ç« ", key="voice_test_text")

        with col2:
            if st.button("ğŸ”Š å†ç”Ÿ", key="voice_speak"):
                if test_text:
                    asyncio.run(self.voice.speak_text(test_text))

        # éŸ³å£°è¨­å®šè©³ç´°
        if self.voice.is_audio_available():
            st.subheader("âš™ï¸ éŸ³å£°è¨­å®š")

            col1, col2 = st.columns(2)

            with col1:
                st.markdown("**èª­ã¿ä¸Šã’é€Ÿåº¦**")
                rate = st.slider("é€Ÿåº¦", 80, 200, 120, key="voice_rate")

                st.markdown("**éŸ³ã®é«˜ã•**")
                pitch = st.slider("é«˜ã•", 50, 200, 100, key="voice_pitch")

            with col2:
                st.markdown("**ãƒœãƒªãƒ¥ãƒ¼ãƒ **")
                volume = st.slider("éŸ³é‡", 0.0, 1.0, 0.8, key="voice_volume_master")

                # è¨­å®šã®ä¿å­˜
                if st.button("ğŸ’¾ è¨­å®šã‚’ä¿å­˜", key="save_voice_settings"):
                    voice_settings = {"rate": rate, "pitch": pitch, "volume": volume}
                    st.session_state.voice_settings = voice_settings
                    st.success("éŸ³å£°è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸ")

        # è‡ªå‹•éŸ³å£°èª­ã¿ä¸Šã’è¨­å®š
        st.subheader("ğŸ”„ è‡ªå‹•èª­ã¿ä¸Šã’")

        enable_auto_speak = st.checkbox("éŸ³å£°å‡ºåŠ›ã‚’æœ‰åŠ¹åŒ–", value=False, key="auto_voice_enabled")

        if enable_auto_speak:
            st.info("ğŸ”Š AIã®å›ç­”ã‚’è‡ªå‹•ã§éŸ³å£°å‡ºåŠ›ã—ã¾ã™")
        else:
            st.info("ğŸ”‡ éŸ³å£°å‡ºåŠ›ã¯ç„¡åŠ¹ã§ã™")

    def start_voice_recording(self):
        """éŸ³å£°éŒ²éŸ³ã‚’é–‹å§‹"""
        if not self.voice.is_audio_available():
            st.error("éŸ³å£°æ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return

        def process_voice_input(transcript: str):
            """éŸ³å£°å…¥åŠ›ã‚’å‡¦ç†"""
            if "voice_transcript" not in st.session_state:
                st.session_state.voice_transcript = []

            st.session_state.voice_transcript.append({"text": transcript, "timestamp": datetime.now().isoformat()})

            # éŸ³å£°ã‚³ãƒãƒ³ãƒ‰ã¨ã—ã¦å‡¦ç†
            self.voice_commands.process_voice_command(
                transcript, lambda cmd, info: self.handle_voice_command(cmd, info)
            )

        # ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œ
        st.experimental_rerun()

    def stop_voice_recording(self):
        """éŸ³å£°éŒ²éŸ³ã‚’åœæ­¢"""
        self.voice.stop_voice_input()
        if "voice_input_active" in st.session_state:
            st.session_state.voice_input_active = False

    def handle_voice_command(self, command: str, info: Dict) -> None:
        """éŸ³å£°ã‚³ãƒãƒ³ãƒ‰ã‚’å‡¦ç†"""
        command_type = info.get("type", "unknown")
        action = info.get("action", command)

        if "command_history" not in st.session_state:
            st.session_state.command_history = []

        st.session_state.command_history.append(
            {"command": command, "type": command_type, "action": action, "timestamp": datetime.now().isoformat()}
        )

        # æ—¢å­˜ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ
        if command_type in self.voice_commands.activated_commands:
            self._execute_activated_command(command_type)

        st.success(f"ğŸ¤ ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œ: {command}")

    def _execute_activated_command(self, command_type: str) -> None:
        """æ—¢å®šã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ"""
        if command_type == "buy":
            st.session_state.quick_trade_action = "buy"
            st.session_state.quick_trade_ticker = "7203"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            st.session_state.quick_trade_amount = 100000
            st.experimental_rerun()

        elif command_type == "sell":
            st.session_state.quick_trade_action = "sell"
            st.session_state.quick_trade_ticker = "7203"
            st.session_state.quick_trade_amount = 50
            st.experimental_rerun()

        elif command_type == "portfolio_check":
            st.session_state.show_portfolio = True
            st.experimental_rerun()

        elif command_type == "analysis":
            st.session_state.show_analysis = True
            st.experimental_rerun()

        elif command_type == "assistant":
            st.session_state.show_ai_assistant = True
            st.experimental_rerun()


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
voice_interface = VoiceInterface()
voice_commands = VoiceCommands()
voice_ui = VoiceControlledUI(voice_interface)


def show_voice_control_page():
    """éŸ³å£°åˆ¶å¾¡ãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤º"""
    st.title("ğŸ¤ éŸ³å£°åˆ¶å¾¡ã¨AIã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹")
    st.markdown("éŸ³å£°ã«ã‚ˆã‚‹æ“ä½œã¨AIå¯¾è©±ã‚’å®Ÿç¾")

    voice_ui.show_voice_interface()

    # éŸ³å£°æ©Ÿèƒ½ã®çŠ¶æ…‹
    if not voice_interface.is_audio_available():
        st.warning("âš ï¸ éŸ³å£°æ©Ÿèƒ½ã‚’åˆ©ç”¨ã™ã‚‹ã«ã¯è¿½åŠ ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå¿…è¦ã§ã™")
        st.markdown(
            """
        ```bash
        pip install SpeechRecognition pyttsx3 pydub sounddevice
        ```
        """
        )

        st.markdown(
            """
        ### ğŸ“¦ å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª
        - **SpeechRecognition**: éŸ³å£°èªè­˜
        - **pyttsx3**: éŸ³å£°åˆæˆ
        - **pydub**: éŸ³å£°å‡¦ç†
        - **sounddevice**: éŸ³å£°ãƒ‡ãƒã‚¤ã‚¹åˆ¶å¾¡
        """
        )

    # éŸ³å£°æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ
    st.markdown("---")
    st.subheader("ğŸ§ª æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ")

    # éŸ³å£°èªè­˜ãƒ†ã‚¹ãƒˆ
    if voice_interface.is_audio_available():
        if st.button("ğŸ¤ éŸ³å£°èªè­˜ãƒ†ã‚¹ãƒˆ"):
            with st.spinner("éŸ³å£°èªè­˜ãƒ†ã‚¹ãƒˆä¸­..."):
                result = asyncio.run(voice_interface.start_voice_input(show_voice_control_page.process_voice_input))

            if result:
                st.success(f"âœ… éŸ³å£°èªè­˜æˆåŠŸ: {result}")
            else:
                st.error("âŒ éŸ³å£°èªè­˜ã«å¤±æ•—ã—ã¾ã—ãŸ")

    # éŸ³å£°èª­ã¿ä¸Šã’ãƒ†ã‚¹ãƒˆ
    if voice_interface.is_audio_available():
        test_texts = [
            "ã“ã‚“ã«ã¡ã¯ã€AGStockã¸ã‚ˆã†ã“ã",
            "ç¾åœ¨ã®ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªçŠ¶æ³ã‚’æ•™ãˆã¦",
            "ãƒˆãƒ¨ã‚¿è‡ªå‹•è»Šã®æ ªä¾¡ã‚’åˆ†æã—ã¦ãã ã•ã„",
            "æœ¬æ—¥ã®å¸‚å ´ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’èª¬æ˜ã—ã¦ãã ã•ã„",
        ]

        selected_text = st.selectbox("ãƒ†ã‚¹ãƒˆæ–‡ç« é¸æŠ", test_texts, key="voice_test_selection")

        if st.button("ğŸ”Š éŸ³å£°èª­ã¿ä¸Šã’ãƒ†ã‚¹ãƒˆ"):
            with st.spinner("éŸ³å£°èª­ã¿ä¸Šã’ä¸­..."):
                result = asyncio.run(voice_interface.speak_text(selected_text))

            if result:
                st.success(f"âœ… éŸ³å£°èª­ã¿ä¸Šã’å®Œäº†")
                st.audio("data:audio/mp3;base64,UklGRi9wBBMKKbN", format="audio/mp3")
            else:
                st.error("âŒ éŸ³å£°èª­ã¿ä¸Šã’ã«å¤±æ•—ã—ã¾ã—ãŸ")


if __name__ == "__main__":
    show_voice_control_page()
