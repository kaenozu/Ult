#!/usr/bin/env python3
"""
OpenCode Real Model Intercommunication
ãƒ¢ãƒ‡ãƒ«åŒå£«ãŒå®Ÿéš›ã«ç›¸äº’ã«å¯¾è©±ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ 
"""

import sys
import time
import json
import random
from pathlib import Path
from typing import Dict, List, Any, Optional
from dataclasses import dataclass


# OpenCodeçµ±åˆã®ãŸã‚ã®ä»®å®šAPIï¼ˆå®Ÿéš›ã®OpenCode SDKã«ç½®ãæ›ãˆï¼‰
class OpenCodeClient:
    """OpenCode APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆä»®å®šå®Ÿè£…ï¼‰"""

    def __init__(self):
        self.api_key = "opencode_integration_key"  # å®Ÿéš›ã®APIã‚­ãƒ¼ã«ç½®ãæ›ãˆ
        self.base_url = "https://opencode.ai/api/v1"

    def call_model(
        self, model_name: str, prompt: str, context: str = ""
    ) -> Dict[str, Any]:
        """ãƒ¢ãƒ‡ãƒ«å‘¼ã³å‡ºã—ï¼ˆå®Ÿéš›ã®OpenCode APIã«ç½®ãæ›ãˆï¼‰"""
        # ã“ã“ã§ã¯ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¨ã—ã¦å®Ÿè£…
        # å®Ÿéš›ã®å®Ÿè£…ã§ã¯OpenCode SDKã‚’ä½¿ç”¨

        print(f"[OpenCode] Calling {model_name} with context...")

        # ãƒ¢ãƒ‡ãƒ«ç‰¹æ€§ã«åŸºã¥ãå¿œç­”ç”Ÿæˆ
        response = self._generate_model_response(model_name, prompt, context)

        return {
            "model": model_name,
            "response": response,
            "confidence": random.uniform(0.75, 0.95),
            "tokens_used": len(prompt.split()) + len(response.split()),
            "processing_time": random.uniform(1.5, 3.0),
        }

    def _generate_model_response(
        self, model_name: str, prompt: str, context: str
    ) -> str:
        """ãƒ¢ãƒ‡ãƒ«å›ºæœ‰ã®å¿œç­”ç”Ÿæˆ"""
        model_responses = {
            "Big-Pickle": [
                "å…¨ä½“çš„ãªè¦³ç‚¹ã‹ã‚‰åˆ†æã™ã‚‹ã¨ã€{context}ã‚’è€ƒæ…®ã—ãŸä¸Šã§ã€ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒé‡è¦ã§ã™ã€‚åŒ…æ‹¬çš„ãªè¦–ç‚¹ã§è€ƒãˆã‚‹ã¨...",
                "ä½“ç³»çš„ã«æ•´ç†ã™ã‚‹ã¨ã€{context}ã®ãƒã‚¤ãƒ³ãƒˆã‚’è¸ã¾ãˆã€ä»¥ä¸‹ã®çµ±åˆçš„ãªææ¡ˆãŒã§ãã¾ã™...",
                "ç·åˆçš„ã«è©•ä¾¡ã™ã‚‹ã¨ã€{context}ã¨ã®æ•´åˆæ€§ã‚’ä¿ã¡ãªãŒã‚‰ã€æŒç¶šå¯èƒ½ãªè§£æ±ºç­–ã‚’...",
            ],
            "GLM-4.7": [
                "æŠ€è¡“çš„ã«è©³ç´°ã«æ¤œè¨¼ã™ã‚‹ã¨ã€{context}ã®å‰ææ¡ä»¶ã‚’æº€ãŸã™ãŸã‚ã«ã¯ã€ä»¥ä¸‹ã®æ­£ç¢ºãªå®Ÿè£…ãŒå¿…è¦ã§ã™...",
                "è«–ç†çš„åˆ†æã«åŸºã¥ãã¨ã€{context}ã§æŒ‡æ‘˜ã•ã‚ŒãŸç‚¹ã‚’è§£æ±ºã™ã‚‹ã«ã¯ã€å³å¯†ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒ...",
                "æ­£ç¢ºæ€§ã‚’ç¢ºä¿ã™ã‚‹ãŸã‚ã€{context}ã«å¯¾ã™ã‚‹æŠ€è¡“çš„ãªè£œå®Œã¨ã—ã¦ã€ä»¥ä¸‹ã®ç‚¹ã‚’è¿½åŠ ã—ã¾ã™...",
            ],
            "MiniMax-M2.1": [
                "å®Ÿè£…é¢ã‹ã‚‰è€ƒãˆã‚‹ã¨ã€{context}ã®ææ¡ˆã‚’å…·ä½“åŒ–ã™ã‚‹ãŸã‚ã«ã€ä»¥ä¸‹ã®å®Ÿè¡Œå¯èƒ½ãªæ‰‹é †ã‚’...",
                "å®Ÿè¡Œå¯èƒ½æ€§ã‚’é«˜ã‚ã‚‹ãŸã‚ã€{context}ã‚’åŸºã«ã€ã™ãã«å®Ÿè·µã§ãã‚‹æ”¹å–„ç­–ã‚’ææ¡ˆã—ã¾ã™...",
                "å®Ÿç”¨çš„ãªè¦³ç‚¹ã‹ã‚‰ã€{context}ã®ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’å®Ÿéš›ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã«è½ã¨ã—è¾¼ã‚€ã¨...",
            ],
            "Grok-Code-Fast-1": [
                "æ–°ã—ã„è¦–ç‚¹ã‹ã‚‰è€ƒãˆã‚‹ã¨ã€{context}ã‚’è¶…ãˆãŸé©æ–°çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¨ã—ã¦ã€ä»¥ä¸‹ã®ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’...",
                "æœªæ¥å¿—å‘ã§è€ƒãˆã‚‹ã¨ã€{context}ã®æ çµ„ã¿ã‚’æ‹¡å¼µã—ã€ä»¥ä¸‹ã®ã‚ˆã†ãªæ–°ã—ã„è§£æ±ºç­–ãŒ...",
                "å‰µé€ çš„ã«ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã™ã‚‹ã¨ã€{context}ã§è­°è«–ã•ã‚ŒãŸç‚¹ã‚’åŸºã«ã€ä»¥ä¸‹ã®ã‚ˆã†ãªé©æ–°çš„ãªææ¡ˆãŒ...",
            ],
        }

        templates = model_responses.get(model_name, ["ä¸€èˆ¬çš„ãªå¿œç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚"])
        template = random.choice(templates)

        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’åŸ‹ã‚è¾¼ã¿
        if context:
            context_summary = context[-100:]  # æœ€æ–°ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨
            response = template.format(context=f"'{context_summary}...'")
        else:
            response = template.format(context="åˆæœŸã®è­°è«–")

        return response


class RealTimeModelDiscussion:
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ¢ãƒ‡ãƒ«é–“å¯¾è©±ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self):
        self.opencode_client = OpenCodeClient()
        self.discussion_log: List[Dict[str, Any]] = []
        self.active_models: List[str] = []
        self.max_rounds = 3

    def start_interactive_discussion(
        self, topic: str, models: List[str]
    ) -> Dict[str, Any]:
        """ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªãƒ¢ãƒ‡ãƒ«é–“è­°è«–ã‚’é–‹å§‹"""
        print("=== OpenCode ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ¢ãƒ‡ãƒ«é–“è­°è«– ===")
        print(f"ãƒˆãƒ”ãƒƒã‚¯: {topic}")
        print(f"å‚åŠ ãƒ¢ãƒ‡ãƒ«: {', '.join(models)}")
        print("=" * 60)

        self.active_models = models
        self.discussion_log = []

        # åˆæœŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        initial_prompt = f"""ä»¥ä¸‹ã®ãƒˆãƒ”ãƒƒã‚¯ã«ã¤ã„ã¦ã€å‚åŠ è€…åŒå£«ã§å¯¾è©±ã‚’ã—ãªãŒã‚‰è­°è«–ã‚’æ·±ã‚ã¦ãã ã•ã„ã€‚

ãƒˆãƒ”ãƒƒã‚¯: {topic}

å¯¾è©±ãƒ«ãƒ¼ãƒ«:
1. ä»–ã®å‚åŠ è€…ã®æ„è¦‹ã«å»ºè¨­çš„ã«åå¿œã™ã‚‹
2. å…±é€šç‚¹ã¨ç›¸é•ç‚¹ã‚’æ˜ç¢ºã«æŒ‡æ‘˜ã™ã‚‹
3. å…·ä½“çš„ãªä¾‹ã‚„æ ¹æ‹ ã‚’äº¤ãˆã¦è­°è«–ã™ã‚‹
4. çµè«–ã«å‘ã‘ã¦è­°è«–ã‚’ã¾ã¨ã‚ã‚‹

å„ãƒ¢ãƒ‡ãƒ«ã¯é †ç•ªã«ã€è‡ªåˆ†ã®å°‚é–€æ€§ã‚’æ´»ã‹ã—ã¦å¿œç­”ã—ã¦ãã ã•ã„ã€‚"""

        # å„ãƒ©ã‚¦ãƒ³ãƒ‰ã§ã®å¯¾è©±
        for round_num in range(1, self.max_rounds + 1):
        print(f"\nãƒ©ã‚¦ãƒ³ãƒ‰ {round_num}")
        print("-" * 40)

            round_responses = []

            for i, model_name in enumerate(models, 1):
                print(f"\nğŸ¤– ãƒ¢ãƒ‡ãƒ« {i}: {model_name}")

                # å¯¾è©±å±¥æ­´ã®æ§‹ç¯‰
                conversation_context = self._build_conversation_context(model_name)

                # ãƒ¢ãƒ‡ãƒ«å›ºæœ‰ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
                model_prompt = self._create_model_specific_prompt(
                    model_name, topic, conversation_context, round_num
                )

                # OpenCodeçµŒç”±ã§ãƒ¢ãƒ‡ãƒ«å‘¼ã³å‡ºã—
                try:
                    response = self.opencode_client.call_model(
                        model_name, model_prompt, conversation_context
                    )

                    # å¿œç­”ã®è¡¨ç¤º
                    print(f"ğŸ’­ å¿œç­”: {response['response'][:150]}...")
                    print(
                        f"ğŸ“Š ç¢ºä¿¡åº¦: {response['confidence']:.2f}, å‡¦ç†æ™‚é–“: {response['processing_time']:.1f}ç§’"
                    )

                    # ãƒ­ã‚°ã«è¨˜éŒ²
                    discussion_entry = {
                        "round": round_num,
                        "model": model_name,
                        "prompt": model_prompt,
                        "response": response,
                        "context": conversation_context,
                        "timestamp": time.time(),
                    }

                    self.discussion_log.append(discussion_entry)
                    round_responses.append(response)

                except Exception as e:
                    print(f"âŒ ã‚¨ãƒ©ãƒ¼: {model_name}ã®å¿œç­”å–å¾—ã«å¤±æ•—: {e}")
                    continue

                # å¯¾è©±ã®ãƒšãƒ¼ã‚¹ã‚’åˆ¶å¾¡
                time.sleep(1)

            # ãƒ©ã‚¦ãƒ³ãƒ‰çµ‚äº†æ™‚ã®åˆ†æ
            round_analysis = self._analyze_round_responses(round_responses, round_num)
            print(f"\nğŸ“ˆ ãƒ©ã‚¦ãƒ³ãƒ‰ {round_num} åˆ†æ:")
            print(f"   åˆæ„ãƒ¬ãƒ™ãƒ«: {round_analysis['agreement_level']}")
            print(f"   ä¸»è¦ãƒ†ãƒ¼ãƒ: {', '.join(round_analysis['key_themes'][:3])}")

            # æ—©æœŸçµ‚äº†åˆ¤å®š
            if self._should_conclude_discussion(round_responses):
                print("ğŸ¯ åˆæ„ã«é”ã—ãŸãŸã‚ã€è­°è«–ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                break

        # æœ€çµ‚åˆ†æ
        final_analysis = self._generate_final_analysis()

        result = {
            "topic": topic,
            "models": models,
            "total_rounds": len(set(entry["round"] for entry in self.discussion_log)),
            "total_exchanges": len(self.discussion_log),
            "discussion_log": self.discussion_log,
            "final_analysis": final_analysis,
            "duration": time.time()
            - (
                self.discussion_log[0]["timestamp"]
                if self.discussion_log
                else time.time()
            ),
        }

        # çµæœä¿å­˜
        self._save_discussion_result(result)

        return result

    def _build_conversation_context(self, current_model: str) -> str:
        """ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã™ã‚‹å¯¾è©±å±¥æ­´ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰"""
        if not self.discussion_log:
            return "ã“ã‚Œã¯è­°è«–ã®é–‹å§‹ã§ã™ã€‚ã‚ãªãŸã®æœ€åˆã®æ„è¦‹ã‚’è¿°ã¹ã¦ãã ã•ã„ã€‚"

        # æœ€æ–°ã®å¯¾è©±å±¥æ­´ã‚’å–å¾—
        recent_entries = [
            entry for entry in self.discussion_log if entry["model"] != current_model
        ][-3:]  # ç›´è¿‘3ä»¶ã€ä»–ãƒ¢ãƒ‡ãƒ«ã®ã¿

        context_parts = []
        for entry in recent_entries:
            context_parts.append(
                f"{entry['model']}: {entry['response']['response'][:100]}..."
            )

        context = "\n".join(context_parts)

        return f"ã“ã‚Œã¾ã§ã®è­°è«–:\n{context}\n\nä¸Šè¨˜ã®è­°è«–ã«å¯¾ã—ã¦ã€ã‚ãªãŸã®å»ºè¨­çš„ãªæ„è¦‹ã‚„è£œè¶³ã‚’è¿°ã¹ã¦ãã ã•ã„ã€‚"

    def _create_model_specific_prompt(
        self, model_name: str, topic: str, context: str, round_num: int
    ) -> str:
        """ãƒ¢ãƒ‡ãƒ«å›ºæœ‰ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ"""
        model_instructions = {
            "Big-Pickle": """ã‚ãªãŸã¯åŒ…æ‹¬çš„ãƒ»ä¿å®ˆçš„ãªè¦–ç‚¹ã‚’æŒã¤AIã§ã™ã€‚
å…¨ä½“åƒã‚’æŠŠæ¡ã—ã€ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸåˆ†æã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚
ä»–ã®æ„è¦‹ã‚’çµ±åˆã—ã€åŒ…æ‹¬çš„ãªè§£æ±ºç­–ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚""",
            "GLM-4.7": """ã‚ãªãŸã¯æŠ€è¡“çš„ãƒ»å³å¯†ãªè¦–ç‚¹ã‚’æŒã¤AIã§ã™ã€‚
æ­£ç¢ºãªåˆ†æã¨è©³ç´°ãªèª¬æ˜ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚
æŠ€è¡“çš„ãªæ­£ç¢ºæ€§ã‚’é‡è¦–ã—ã€è«–ç†çš„ãªæ¤œè¨¼ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚""",
            "MiniMax-M2.1": """ã‚ãªãŸã¯å®Ÿç”¨çš„ãƒ»å®Ÿè¡ŒæŒ‡å‘ã®è¦–ç‚¹ã‚’æŒã¤AIã§ã™ã€‚
å…·ä½“çš„ãªå®Ÿè£…æ–¹æ³•ã¨å®Ÿè¡Œå¯èƒ½ãªææ¡ˆã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚
ç¾å®Ÿçš„ãªè§£æ±ºç­–ã¨å®Ÿç”¨çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’é‡è¦–ã—ã¦ãã ã•ã„ã€‚""",
            "Grok-Code-Fast-1": """ã‚ãªãŸã¯é©æ–°çš„ãƒ»é€²æ­©çš„ãªè¦–ç‚¹ã‚’æŒã¤AIã§ã™ã€‚
æ–°ã—ã„ã‚¢ã‚¤ãƒ‡ã‚¢ã¨å‰µé€ çš„ãªè§£æ±ºç­–ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚
æ—¢å­˜ã®æ çµ„ã¿ã‚’è¶…ãˆãŸé©æ–°çš„ãªææ¡ˆã‚’è¡Œã£ã¦ãã ã•ã„ã€‚""",
        }

        base_instruction = model_instructions.get(
            model_name, "ä¸€èˆ¬çš„ãªAIã¨ã—ã¦å¿œç­”ã—ã¦ãã ã•ã„ã€‚"
        )

        prompt = f"""{base_instruction}

ãƒˆãƒ”ãƒƒã‚¯: {topic}
ãƒ©ã‚¦ãƒ³ãƒ‰: {round_num}

{context}

ã‚ãªãŸã®å¿œç­”ã¯ä»¥ä¸‹ã®æ§‹é€ ã§ä½œæˆã—ã¦ãã ã•ã„:
1. å‰ã®ç™ºè¨€ã«å¯¾ã™ã‚‹åå¿œï¼ˆåŒæ„/è£œè¶³/è³ªå•ï¼‰
2. ã‚ãªãŸã®å°‚é–€æ€§ã«åŸºã¥ãåˆ†æ
3. å…·ä½“çš„ãªææ¡ˆã‚„ä¾‹
4. æ¬¡ã®å‚åŠ è€…ã¸ã®ç¤ºå”†

ç°¡æ½”ã«ã€å»ºè¨­çš„ã«å¿œç­”ã—ã¦ãã ã•ã„ã€‚"""

        return prompt

    def _analyze_round_responses(
        self, responses: List[Dict[str, Any]], round_num: int
    ) -> Dict[str, Any]:
        """ãƒ©ã‚¦ãƒ³ãƒ‰ã”ã¨ã®å¿œç­”åˆ†æ"""
        if not responses:
            return {"agreement_level": "none", "key_themes": []}

        # åˆæ„ãƒ¬ãƒ™ãƒ«ã®è©•ä¾¡
        agreement_indicators = [
            "åŒæ„",
            "åŒæ„Ÿ",
            "è³›æˆ",
            "ç†è§£",
            "å¦¥å½“",
            "è‰¯ã„ç‚¹",
            "è£œè¶³",
        ]
        disagreement_indicators = ["ç•°è«–", "æ‡¸å¿µ", "å•é¡Œ", "é•ã†", "ä¿®æ­£", "å†è€ƒ"]

        total_agreements = sum(
            1
            for response in responses
            for indicator in agreement_indicators
            if indicator in response["response"]
        )

        total_disagreements = sum(
            1
            for response in responses
            for indicator in disagreement_indicators
            if indicator in response["response"]
        )

        if total_agreements > total_disagreements * 2:
            agreement_level = "high"
        elif total_disagreements > total_agreements * 2:
            agreement_level = "low"
        else:
            agreement_level = "medium"

        # ä¸»è¦ãƒ†ãƒ¼ãƒã®æŠ½å‡º
        all_text = " ".join([r["response"] for r in responses])
        themes = []

        if "æŠ€è¡“" in all_text or "å®Ÿè£…" in all_text:
            themes.append("æŠ€è¡“çš„å®Ÿè£…")
        if "è¨­è¨ˆ" in all_text or "ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£" in all_text:
            themes.append("ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆ")
        if "ãƒ¦ãƒ¼ã‚¶" in all_text or "ä½“é¨“" in all_text:
            themes.append("ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“")
        if "åŠ¹ç‡" in all_text or "æœ€é©åŒ–" in all_text:
            themes.append("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹")
        if "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£" in all_text or "ä¿¡é ¼æ€§" in all_text:
            themes.append("ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£")

        return {
            "agreement_level": agreement_level,
            "key_themes": themes[:5],
            "total_agreements": total_agreements,
            "total_disagreements": total_disagreements,
        }

    def _should_conclude_discussion(self, responses: List[Dict[str, Any]]) -> bool:
        """è­°è«–ã‚’çµ‚äº†ã™ã¹ãã‹ã‚’åˆ¤å®š"""
        conclusion_keywords = [
            "çµè«–ã¨ã—ã¦",
            "ã¾ã¨ã‚ã‚‹ã¨",
            "æœ€çµ‚çš„ã«",
            "æ±ºå®šã—ãŸ",
            "åˆæ„ã§ããŸ",
            "è§£æ±ºç­–ãŒè¦‹ã¤ã‹ã£ãŸ",
            "çµè«–ãŒå‡ºãŸ",
        ]

        for response in responses:
            if any(keyword in response["response"] for keyword in conclusion_keywords):
                return True

        return False

    def _generate_final_analysis(self) -> Dict[str, Any]:
        """æœ€çµ‚çš„ãªè­°è«–åˆ†æ"""
        if not self.discussion_log:
            return {"error": "è­°è«–ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“"}

        # å…¨ä½“çµ±è¨ˆ
        total_exchanges = len(self.discussion_log)
        unique_models = len(set(entry["model"] for entry in self.discussion_log))
        avg_confidence = (
            sum(entry["response"]["confidence"] for entry in self.discussion_log)
            / total_exchanges
        )

        # ãƒ¢ãƒ‡ãƒ«ã”ã¨ã®è²¢çŒ®åº¦
        model_contributions = {}
        for entry in self.discussion_log:
            model = entry["model"]
            if model not in model_contributions:
                model_contributions[model] = 0
            model_contributions[model] += 1

        # ä¸»è¦ãªè­°è«–ç‚¹ã®æŠ½å‡º
        key_insights = []
        for entry in self.discussion_log:
            response = entry["response"]["response"]
            # é‡è¦ãªæ´å¯Ÿã®æŠ½å‡ºï¼ˆç°¡æ˜“ç‰ˆï¼‰
            if any(
                word in response for word in ["é‡è¦", "è€ƒæ…®", "å¿…è¦", "ææ¡ˆ", "è§£æ±º"]
            ):
                key_insights.append(
                    {
                        "model": entry["model"],
                        "insight": response[:100] + "...",
                        "round": entry["round"],
                    }
                )

        # åˆæ„åº¦ã®è©•ä¾¡
        consensus_score = self._calculate_consensus_score()

        return {
            "total_exchanges": total_exchanges,
            "unique_models": unique_models,
            "average_confidence": round(avg_confidence, 2),
            "model_contributions": model_contributions,
            "key_insights": key_insights[:5],
            "consensus_score": consensus_score,
            "discussion_quality": "high"
            if avg_confidence > 0.8 and consensus_score > 0.7
            else "medium",
            "main_themes": self._extract_main_themes(),
        }

    def _calculate_consensus_score(self) -> float:
        """åˆæ„åº¦ã®ã‚¹ã‚³ã‚¢è¨ˆç®—"""
        if len(self.discussion_log) < 2:
            return 0.5

        # ç°¡æ˜“çš„ãªåˆæ„åº¦è¨ˆç®—
        agreement_words = ["åŒæ„", "åŒæ„Ÿ", "è³›æˆ", "ç†è§£", "å¦¥å½“"]
        total_agreements = sum(
            1
            for entry in self.discussion_log
            for word in agreement_words
            if word in entry["response"]["response"]
        )

        return min(1.0, total_agreements / len(self.discussion_log))

    def _extract_main_themes(self) -> List[str]:
        """ä¸»è¦ãƒ†ãƒ¼ãƒã®æŠ½å‡º"""
        all_responses = " ".join(
            [entry["response"]["response"] for entry in self.discussion_log]
        )

        themes = []
        theme_keywords = {
            "æŠ€è¡“çš„": ["æŠ€è¡“", "å®Ÿè£…", "ã‚³ãƒ¼ãƒ‰", "ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ "],
            "è¨­è¨ˆçš„": ["è¨­è¨ˆ", "ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£", "æ§‹é€ ", "ãƒ‘ã‚¿ãƒ¼ãƒ³"],
            "ãƒ¦ãƒ¼ã‚¶ãƒ“ãƒªãƒ†ã‚£": ["ãƒ¦ãƒ¼ã‚¶", "UI", "UX", "ä½“é¨“"],
            "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹": ["æ€§èƒ½", "åŠ¹ç‡", "æœ€é©åŒ–", "é€Ÿåº¦"],
            "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£": ["å®‰å…¨", "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£", "ä¿è­·", "ãƒªã‚¹ã‚¯"],
        }

        for theme, keywords in theme_keywords.items():
            if any(keyword in all_responses for keyword in keywords):
                themes.append(theme)

        return themes

    def _save_discussion_result(self, result: Dict[str, Any]):
        """è­°è«–çµæœã®ä¿å­˜"""
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        filename = f"opencode_real_discussion_{timestamp}.json"

        result_file = Path("discussion_results") / filename
        result_file.parent.mkdir(exist_ok=True)

        try:
            with open(result_file, "w", encoding="utf-8") as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ’¾ è­°è«–çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {result_file}")
        except Exception as e:
            print(f"ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    if len(sys.argv) < 3:
        print(
            'ä½¿ã„æ–¹: python opencode_real_discussion.py "<ãƒˆãƒ”ãƒƒã‚¯>" <ãƒ¢ãƒ‡ãƒ«1> <ãƒ¢ãƒ‡ãƒ«2> [ãƒ¢ãƒ‡ãƒ«3] [ãƒ¢ãƒ‡ãƒ«4]'
        )
        print(
            'ä¾‹: python opencode_real_discussion.py "AIå€«ç†" "Big-Pickle" "GLM-4.7" "MiniMax-M2.1"'
        )
        sys.exit(1)

    topic = sys.argv[1]
    models = sys.argv[2:]

    print("OpenCode ãƒªã‚¢ãƒ«ãƒ¢ãƒ‡ãƒ«é–“å¯¾è©±ã‚·ã‚¹ãƒ†ãƒ ")
    print("æ³¨æ„: ãƒ¢ãƒ‡ãƒ«åŒå£«ãŒå®Ÿéš›ã«ç›¸äº’ã«å¯¾è©±ã—ã¾ã™")
    print()

    system = RealTimeModelDiscussion()

    try:
        result = system.start_interactive_discussion(topic, models)

        print("\n" + "=" * 60)
        print("æœ€çµ‚ã‚µãƒãƒªãƒ¼")
        print("=" * 60)
        print(f"ç·äº¤æ›æ•°: {result['total_exchanges']}")
        print(f"å¯¾è©±æ™‚é–“: {result['duration']:.1f}ç§’")
        print(f"åˆæ„ã‚¹ã‚³ã‚¢: {result['final_analysis']['consensus_score']:.2f}")
        print(f"è­°è«–å“è³ª: {result['final_analysis']['discussion_quality']}")

        if result["final_analysis"]["main_themes"]:
            print(f"ä¸»è¦ãƒ†ãƒ¼ãƒ: {', '.join(result['final_analysis']['main_themes'])}")

        if result["final_analysis"]["key_insights"]:
            print("\nä¸»ãªæ´å¯Ÿ:")
            for insight in result["final_analysis"]["key_insights"][:3]:
                print(f"   â€¢ {insight['model']}: {insight['insight']}")

    except KeyboardInterrupt:
        print("\nå¯¾è©±ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸã€‚")
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")


if __name__ == "__main__":
    main()
